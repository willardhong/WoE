{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 968,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import warnings\n",
    "import math\n",
    "from scipy import stats\n",
    "from collections import Counter\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "### weight of evidence ------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from https://stackoverflow.com/questions/50352210/woe-and-iv-table-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 969,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_iv(df, feature, target, pr=0):\n",
    "    lst = []\n",
    "\n",
    "    for i in range(df[feature].nunique()):\n",
    "        val = list(df[feature].unique())[i]\n",
    "        lst.append([feature, val, df[df[feature] == val].count()[feature], df[(df[feature] == val) & (df[target] == 1)].count()[feature]])\n",
    " \n",
    "    data = pd.DataFrame(lst, columns=['Variable', 'Value', 'Pop', 'Bad'])\n",
    "    data['Good'] = data['Pop'] - data['Bad']\n",
    "    \n",
    "    data['Badx'] = data['Bad'] + 0.01\n",
    "    data['Goodx'] = data['Good'] + 0.01\n",
    "    \n",
    "    data['Pop'] = data['Good'] + data['Bad']\n",
    "    data['Popx'] = data['Goodx'] + data['Badx']\n",
    "    \n",
    "    data['Dist Good'] = round((data['Pop'] - data['Bad']) / (data['Pop'].sum() - data['Bad'].sum()), 4)\n",
    "    data['Dist Bad'] = round(data['Bad'] / data['Bad'].sum(), 4)\n",
    "    \n",
    "    data['Dist Goodx'] = (data['Popx'] - data['Badx']) / (data['Popx'].sum() - data['Badx'].sum())\n",
    "    data['Dist Badx'] = data['Badx'] / data['Badx'].sum()\n",
    "    \n",
    "    data['Dist Pop'] = round(data['Pop'] / data['Pop'].sum(), 4)\n",
    "    data['Bad Rate'] = round(data['Bad'] / data['Pop'], 4)\n",
    "    data['grp_score'] = round((data['Dist Good']/(data['Dist Good'] + data['Dist Bad']))*10, 2)\n",
    "    \n",
    "    data['WoE'] = np.log(data['Dist Goodx'] / data['Dist Badx'])\n",
    "    data['IV'] = data['WoE'] * (data['Dist Goodx'] - data['Dist Badx'])\n",
    "    \n",
    "    data['Efficiency'] =  abs(data['Dist Good'] - data['Dist Bad'])/2  \n",
    "    \n",
    "    data = data.sort_values(by=['Variable', 'Value'], ascending=True)\n",
    "    data = data.reset_index()\n",
    "    mydf = data[[\n",
    "       'Value',\n",
    "       'Good', 'Bad',\n",
    "       'Dist Good','Dist Bad',\n",
    "       'WoE',\n",
    "       'IV'\n",
    "    ]]\n",
    "\n",
    "    #mydf=pd.DataFrame(data=d)\n",
    "   \n",
    "    if pr == 1:\n",
    "        print(mydf)\n",
    "        \n",
    "    total_iv = data['IV'].sum()\n",
    "    print(total_iv)\n",
    "\n",
    "    #return data['IV'].values[0]\n",
    "    #return mydf.values\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 970,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', header=None)\n",
    "iris.columns = ['sepal_l', 'sepal_w', 'petal_l', 'petal_w', 'type']\n",
    "\n",
    "df = pd.get_dummies(iris.type)['Iris-setosa'].to_frame()\n",
    "iris = iris.merge(df, left_index=True, right_index=True)\n",
    "\n",
    "iris = iris.drop(['type','sepal_w','petal_l','petal_w'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 971,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = iris.rename(columns = {'Iris-setosa': 'target'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 972,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_l  target\n",
      "0      5.1       1\n",
      "1      4.9       1\n",
      "2      4.7       1\n",
      "3      4.6       1\n",
      "4      5.0       1\n"
     ]
    }
   ],
   "source": [
    "print(iris.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1045,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.593408</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.476526</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.397855</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.068536</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.735488</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x  target\n",
       "0  0.593408       0\n",
       "1 -0.476526       0\n",
       "2  1.397855       0\n",
       "3  2.068536       0\n",
       "4  1.735488       0"
      ]
     },
     "execution_count": 1045,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = pd.DataFrame(np.random.normal(1, 1, 1000))\n",
    "t['target'] = 0\n",
    "u = pd.DataFrame(np.random.normal(2, 1, 1000))\n",
    "u['target'] = 1\n",
    "data = pd.concat([t, u])\n",
    "data.columns = ['x', 'target']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1046,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>target</th>\n",
       "      <th>cat</th>\n",
       "      <th>tran</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.593408</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.573, 0.608]</td>\n",
       "      <td>0.573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.476526</td>\n",
       "      <td>0</td>\n",
       "      <td>(-0.542, -0.391]</td>\n",
       "      <td>-0.542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.397855</td>\n",
       "      <td>0</td>\n",
       "      <td>(1.387, 1.407]</td>\n",
       "      <td>1.387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.068536</td>\n",
       "      <td>0</td>\n",
       "      <td>(2.052, 2.08]</td>\n",
       "      <td>2.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.735488</td>\n",
       "      <td>0</td>\n",
       "      <td>(1.719, 1.74]</td>\n",
       "      <td>1.719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x  target               cat   tran\n",
       "0  0.593408       0    (0.573, 0.608]  0.573\n",
       "1 -0.476526       0  (-0.542, -0.391] -0.542\n",
       "2  1.397855       0    (1.387, 1.407]  1.387\n",
       "3  2.068536       0     (2.052, 2.08]  2.052\n",
       "4  1.735488       0     (1.719, 1.74]  1.719"
      ]
     },
     "execution_count": 1046,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['cat'] = pd.qcut(data['x'], 100)\n",
    "data['tran'] = data['cat'].apply(lambda x : x.left) \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1047,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Value  Good  Bad  Dist Good  Dist Bad       WoE        IV\n",
      "0      [-inf, -0.542)    71    9      0.071     0.009  2.064486  0.127984\n",
      "1   [-0.542, -0.0583)    84   16      0.084     0.016  1.657722  0.112713\n",
      "2    [-0.0583, 0.761)   256   84      0.256     0.084  1.114281  0.191635\n",
      "3      [0.761, 1.055)    97   63      0.097     0.063  0.431521  0.014670\n",
      "4      [1.055, 1.185)    54   26      0.054     0.026  0.730688  0.020457\n",
      "5      [1.185, 1.519)   120  100      0.120     0.100  0.182305  0.003646\n",
      "6      [1.519, 1.626)    33   27      0.033     0.027  0.200603  0.001203\n",
      "7       [1.626, 1.74)    36   44      0.036     0.044 -0.200620  0.001605\n",
      "8       [1.74, 2.052)   106  134      0.106     0.134 -0.234381  0.006562\n",
      "9      [2.052, 3.052)   115  345      0.115     0.345 -1.098554  0.252640\n",
      "10       [3.052, inf)    28  152      0.028     0.152 -1.691385  0.209709\n",
      "0.9428233065765501\n"
     ]
    }
   ],
   "source": [
    "WOE_Binning(data, 'target', 'tran', p_threshold=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "based loosely on https://github.com/jstephenj14/Monotonic-WOE-Binning-Algorithm/blob/master/Monotonic%20WOE%20Binning.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1028,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WOE_Binning(data, Y, attr, sign = True, p_threshold=0.05):\n",
    "    defaults_threshold = 1\n",
    "    #column = dataset.columns[dataset.columns != Y][0]\n",
    "    column = data[attr]\n",
    "    summary = data.groupby([column]).agg({Y:{\"means\":\"mean\",\"nsamples\":\"size\",\"std_dev\":\"std\"}})\n",
    "    summary.columns = summary.columns.droplevel(level=0)\n",
    "    summary = summary[[\"means\",\"nsamples\",\"std_dev\"]]\n",
    "    summary = summary.reset_index()\n",
    "    summary[\"del_flag\"] = 0\n",
    "    summary[\"std_dev\"] = summary[\"std_dev\"].fillna(0)\n",
    "    summary = summary.sort_values([attr],ascending = sign)\n",
    "    summary.reset_index(inplace = True, drop = True) \n",
    "    \n",
    "    i = 0\n",
    "    while True:\n",
    "        if i > len(summary)-2:\n",
    "            break\n",
    "        else:\n",
    "            i = i + 1;\n",
    "            x = i - 1;\n",
    "           \n",
    "            n_x = summary.iloc[x].nsamples\n",
    "            n_i = summary.iloc[i].nsamples\n",
    "            \n",
    "            n = n_x + n_i\n",
    "            mean_x = summary.iloc[x].means\n",
    "            mean_i = summary.iloc[i].means\n",
    "            \n",
    "            var_x = (summary.iloc[x].std_dev)**2\n",
    "            var_i = (summary.iloc[i].std_dev)**2\n",
    "            \n",
    "            #std deviation\n",
    "            s = np.sqrt((var_x/n_x + var_i/n_i)/2)\n",
    "            p = 0\n",
    "            if s != 0:\n",
    "                t = (mean_x - mean_i)/s\n",
    "                df = 2*(n_x + n_i) - 2\n",
    "                p = 1 - stats.t.cdf(t,df=df)\n",
    "            if (p >= p_threshold) or (s == 0):\n",
    "                #absorb data\n",
    "                summary.loc[i, attr] = summary.loc[x, attr]\n",
    "                summary.loc[i, 'nsamples'] = n_x + n_i\n",
    "                summary.loc[i, 'means'] = (n_x*mean_x + n_i*mean_i)/n\n",
    "                summary.loc[i, 'std_dev'] = np.sqrt(((n_x*var_x)+(n_i*var_i))/n)\n",
    "                summary.loc[x, 'del_flag'] = 1        \n",
    "            continue\n",
    "            \n",
    "    summary = summary[summary['del_flag'] == 0]\n",
    "    summary = summary.reset_index()\n",
    "    l = [-math.inf]\n",
    "    for index, row in summary.iterrows():\n",
    "        if index > 0:\n",
    "            l.append(row[attr])\n",
    "    l.append(math.inf)    \n",
    "    #print(l)\n",
    "    data['mybin'] = pd.cut(x=data[attr], bins=l, right=False)\n",
    "    calc_iv(data, 'mybin', 'target', pr=1)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 977,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Value  Good  Bad  Dist Good  Dist Bad       WoE        IV\n",
      "0  [-inf, 4.9)     0   16       0.00      0.32 -8.071031  2.580956\n",
      "1   [4.9, 5.5)     7   29       0.07      0.58 -2.112950  1.076665\n",
      "2   [5.5, 5.6)     5    2       0.05      0.04  0.220654  0.002188\n",
      "3   [5.6, 5.9)    18    3       0.18      0.06  1.096340  0.131418\n",
      "4   [5.9, inf)    70    0       0.70      0.00  8.161161  5.709143\n",
      "9.500369894639753\n"
     ]
    }
   ],
   "source": [
    "WOE_Binning(iris, 'target', 'sepal_l', p_threshold=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "got this from github..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 975,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chimerge(data, attr, label, max_intervals):\n",
    "    distinct_vals = sorted(set(data[attr])) # Sort the distinct values\n",
    "    labels = sorted(set(data[label]))       # Get all possible labels\n",
    "    empty_count = {l: 0 for l in labels}    # A helper function for padding the Counter()\n",
    "    intervals = [[distinct_vals[i], distinct_vals[i]] for i in range(len(distinct_vals))] # Initialize the intervals for each attribute\n",
    "    while len(intervals) > max_intervals:   # While loop  \n",
    "        chi = []\n",
    "        for i in range(len(intervals)-1):\n",
    "            # Calculate the Chi2 value\n",
    "            obs0 = data[data[attr].between(intervals[i][0], intervals[i][1])]\n",
    "            obs1 = data[data[attr].between(intervals[i+1][0], intervals[i+1][1])]\n",
    "            total = len(obs0) + len(obs1)\n",
    "            count_0 = np.array([v for i, v in {**empty_count, **Counter(obs0[label])}.items()])\n",
    "            count_1 = np.array([v for i, v in {**empty_count, **Counter(obs1[label])}.items()])\n",
    "            count_total = count_0 + count_1\n",
    "            expected_0 = count_total*sum(count_0)/total\n",
    "            expected_1 = count_total*sum(count_1)/total\n",
    "            chi_ = (count_0 - expected_0)**2/expected_0 + (count_1 - expected_1)**2/expected_1\n",
    "            chi_ = np.nan_to_num(chi_) # Deal with the zero counts\n",
    "            chi.append(sum(chi_))      # Finally do the summation for Chi2\n",
    "        min_chi = min(chi)             # Find the minimal Chi2 for current iteration\n",
    "        for i, v in enumerate(chi): \n",
    "            if v == min_chi:\n",
    "                min_chi_index = i      # Find the index of the interval to be merged\n",
    "                break\n",
    "        new_intervals = []             # Prepare for the merged new data array\n",
    "        skip = False\n",
    "        done = False\n",
    "        for i in range(len(intervals)):\n",
    "            if skip:\n",
    "                skip = False\n",
    "                continue\n",
    "            if i == min_chi_index and not done: # Merge the intervals\n",
    "                t = intervals[i] + intervals[i+1]\n",
    "                new_intervals.append([min(t), max(t)])\n",
    "                skip = True\n",
    "                done = True\n",
    "            else:\n",
    "                new_intervals.append(intervals[i])\n",
    "        intervals = new_intervals\n",
    "        \n",
    "   \n",
    "    l = [-math.inf]\n",
    "    for i in intervals:\n",
    "        l.append(i[1])\n",
    "    l.append(math.inf)\n",
    "    print(l)   \n",
    "    data['mybin'] = pd.cut(x=data[attr], bins=l, right=False)\n",
    "    calc_iv(data, 'mybin', 'target', pr=1)\n",
    "    #return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 976,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-inf, 4.8, 5.4, 5.5, 5.8, 7.9, inf]\n",
      "         Value  Good  Bad  Dist Good  Dist Bad       WoE        IV\n",
      "0  [-inf, 4.8)     0   11       0.00      0.22 -7.696522  1.691974\n",
      "1   [4.8, 5.4)     6   29       0.06      0.58 -2.266764  1.177449\n",
      "2   [5.4, 5.5)     1    5       0.01      0.10 -2.294033  0.206431\n",
      "3   [5.5, 5.8)    17    4       0.17      0.08  0.752462  0.067642\n",
      "4   [5.8, 7.9)    75    1       0.75      0.02  3.615123  2.637140\n",
      "5   [7.9, inf)     1    0       0.01      0.00  3.922573  0.038811\n",
      "5.819446171387975\n"
     ]
    }
   ],
   "source": [
    "chimerge(data=iris, attr='sepal_l', label='target', max_intervals=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import the packages\n",
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define 2 random distributions\n",
    "#Sample Size\n",
    "N = 10\n",
    "#Gaussian distributed data with mean = 2 and var = 1\n",
    "a = np.random.randn(N) + 2\n",
    "#Gaussian distributed data with with mean = 0 and var = 1\n",
    "b = np.random.randn(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the Standard Deviation\n",
    "#Calculate the variance to get the standard deviation\n",
    "\n",
    "#For unbiased max likelihood estimate we have to divide the var by N-1, and therefore the parameter ddof = 1\n",
    "var_a = a.var(ddof=1)\n",
    "var_b = b.var(ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36602433831146336 0.7540508106223665\n"
     ]
    }
   ],
   "source": [
    "print(var_a, var_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = 4.20921246738193\n",
      "p = 0.0005273169029311742\n",
      "t = 4.20921246738193\n",
      "p = 0.0005273169029312183\n"
     ]
    }
   ],
   "source": [
    "#std deviation\n",
    "s = np.sqrt((var_a + var_b)/2)\n",
    "#s\n",
    "\n",
    "## Calculate the t-statistics\n",
    "t = (a.mean() - b.mean())/(s*np.sqrt(2/N))\n",
    "\n",
    "## Compare with the critical t-value\n",
    "#Degrees of freedom\n",
    "df = 2*N - 2\n",
    "\n",
    "#p-value after comparison with the t \n",
    "p = 1 - stats.t.cdf(t,df=df)\n",
    "\n",
    "print(\"t = \" + str(t))\n",
    "print(\"p = \" + str(2*p))\n",
    "### You can see that after comparing the t statistic with the critical t value (computed internally) we get a good p value of 0.0005 and thus we reject the null hypothesis and thus it proves that the mean of the two distributions are different and statistically significant.\n",
    "\n",
    "## Cross Checking with the internal scipy function\n",
    "t2, p2 = stats.ttest_ind(a,b)\n",
    "print(\"t = \" + str(t2))\n",
    "print(\"p = \" + str(p2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
